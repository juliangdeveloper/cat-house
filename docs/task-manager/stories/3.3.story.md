# Story 3.3: Task Command Handlers (Create & List)

---

## Status
**Done**

**Created:** November 12, 2025  
**Aligned:** November 12, 2025  
**Assigned:** Dev Agent  
**Completed:** November 12, 2025

---

## Story

**As a** user,  
**I want** to create and list tasks via command actions,  
**so that** I can manage my task list through the Cat House interface.

---

## Acceptance Criteria

1. Create `app/commands/handlers/tasks.py` module
2. Implement `create_task_handler(user_id: str, payload: dict, db)`:
   - Accepts payload: `{ title, description?, status?, priority?, due_date? }`
   - Validates required fields (title) and returns 400 for invalid data
   - Creates task with user_id from command + generated UUID + created_at timestamp
   - Returns created task object with all fields
3. Implement `list_tasks_handler(user_id: str, payload: dict, db)`:
   - Accepts payload: `{ status?: string }` for optional filtering
   - Queries tasks WHERE user_id = command.user_id
   - Applies status filter if provided in payload
   - Returns array of task objects
4. Both handlers use asyncpg for database operations
5. Both handlers include error handling with descriptive messages
6. Register both handlers in ACTION_HANDLERS dictionary: `\"create-task\": create_task_handler`, `\"list-tasks\": list_tasks_handler`
7. Handlers return dict responses compatible with CommandResponse model

---

## Tasks / Subtasks

- [x] **Task 1: Create Task Handlers Module** (AC: 1)
  - [x] Create file: `app/commands/handlers/tasks.py`
  - [x] Import required dependencies:
    - [x] `from fastapi import HTTPException`
    - [x] `from app.models.task import TaskCreate, TaskResponse`
    - [x] `from pydantic import ValidationError`
    - [x] `import structlog`
  - [x] Initialize logger: `logger = structlog.get_logger()`
  - [x] Add module docstring explaining task command handlers

- [x] **Task 2: Implement create_task_handler** (AC: 2, 4, 5, 7)
  - [x] Define function signature: `async def create_task_handler(user_id: str, payload: dict, db) -> dict`
  - [x] Add comprehensive docstring with parameters, returns, and raises documentation
  - [x] Validate payload using TaskCreate model:
    - [x] Try to parse: `task_data = TaskCreate(**payload)`
    - [x] Catch ValidationError and raise HTTPException(400) with error details
  - [x] Prepare SQL INSERT statement with all TaskCreate fields + user_id
  - [x] Execute INSERT using asyncpg:
    - [x] `row = await db.fetchrow(sql, user_id, task_data.title, ...)`
    - [x] Use RETURNING clause to get created task
  - [x] Convert asyncpg Row to TaskResponse:
    - [x] `task_response = TaskResponse.model_validate(row)`
  - [x] Convert TaskResponse to dict:
    - [x] `return task_response.model_dump(mode='json')`
  - [x] Add try/except for database errors:
    - [x] Catch asyncpg exceptions and log error
    - [x] Raise HTTPException(500) with generic error message
  - [x] Log successful task creation with task_id and user_id

- [x] **Task 3: Implement list_tasks_handler** (AC: 3, 4, 5, 7)
  - [x] Define function signature: `async def list_tasks_handler(user_id: str, payload: dict, db) -> dict`
  - [x] Add comprehensive docstring with parameters, returns, and raises documentation
  - [x] Extract optional status filter from payload: `status_filter = payload.get('status')`
  - [x] Build SQL query based on filters:
    - [x] Base query: `SELECT * FROM tasks WHERE user_id = \`
    - [x] If status provided: Add `AND status = \`
    - [x] Add `ORDER BY created_at DESC` for chronological listing
  - [x] Execute query with appropriate parameters:
    - [x] If status: `rows = await db.fetch(sql, user_id, status_filter)`
    - [x] Else: `rows = await db.fetch(sql, user_id)`
  - [x] Convert rows to TaskResponse objects:
    - [x] `tasks = [TaskResponse.model_validate(row).model_dump(mode='json') for row in rows]`
  - [x] Return dict: `return {\"tasks\": tasks, \"count\": len(tasks)}`
  - [x] Add try/except for database errors
  - [x] Log successful query with user_id, status_filter, and result count

- [x] **Task 4: Register Handlers in Command Router** (AC: 6)
  - [x] Open `app/commands/router.py`
  - [x] Import task handlers: `from app.commands.handlers.tasks import create_task_handler, list_tasks_handler`
  - [x] Register in ACTION_HANDLERS dictionary:
    - [x] `\"create-task\": create_task_handler`
    - [x] `\"list-tasks\": list_tasks_handler`
  - [x] Verify handler signature matches expected pattern: `async def handler(user_id: str, payload: dict, db) -> dict`

- [x] **Task 5: Write Unit Tests for Task Handlers** (AC: 2-7)
  - [x] Create test file: `tests/unit/test_task_handlers.py`
  - [x] Import test dependencies: `pytest`, `AsyncMock`, `TaskCreate`, `TaskResponse`
  - [x] Test create_task_handler:
    - [x] Test successful task creation with valid payload
    - [x] Test validation error with missing title (HTTPException 400)
    - [x] Test validation error with invalid status (HTTPException 400)
    - [x] Test database error handling (HTTPException 500)
    - [x] Mock asyncpg db.fetchrow to return test task data
    - [x] Verify returned dict has all task fields
  - [x] Test list_tasks_handler:
    - [x] Test list all tasks (no status filter)
    - [x] Test list with status filter (e.g., status=\"pending\")
    - [x] Test empty result (user has no tasks)
    - [x] Mock asyncpg db.fetch to return list of task rows
    - [x] Verify returned dict has `tasks` array and `count`
  - [x] Use pytest markers: `@pytest.mark.unit` for all tests
  - [x] Run tests: `pytest tests/unit/test_task_handlers.py -v`

- [x] **Task 6: Write Integration Tests for Task Actions** (AC: 2-7)
  - [x] Create test file: `tests/integration/test_task_actions.py`
  - [x] Import test dependencies: `import pytest; import pytest_asyncio; from httpx import AsyncClient`
  - [x] Use shared fixtures from conftest.py: `client`, `test_service_key`, `test_db`
  - [x] Test POST /execute with action=\"create-task\":
    - [x] Mark test with `@pytest.mark.asyncio` and `@pytest.mark.integration`
    - [x] Use async function: `async def test_create_task_success(client, test_service_key, test_db)`
    - [x] Send request: `response = await client.post("/execute", headers={"X-Service-Key": test_service_key}, json={...})`
    - [x] Send valid payload: `{\"action\": \"create-task\", \"user_id\": \"test-user-123\", \"payload\": {\"title\": \"Test Task\"}}`
    - [x] Verify response: `success=true`, `data` contains task object with id, title, user_id
    - [x] Verify task created in database: `await test_db.fetchrow("SELECT * FROM tasks WHERE user_id = 'test-user-123'")`
  - [x] Test POST /execute with action=\"list-tasks\":
    - [x] Create test tasks in database using asyncpg: `await test_db.execute("INSERT INTO tasks ...")`
    - [x] Create at least 3 tasks with different statuses (pending, in_progress, completed)
    - [x] Send request without status filter: `await client.post("/execute", ...)`
    - [x] Verify response contains all tasks for user
    - [x] Send request with status filter: `{\"payload\": {\"status\": \"pending\"}}`
    - [x] Verify response contains only pending tasks
  - [x] Test validation errors:
    - [x] Send create-task with missing title: `await client.post(...)`
    - [x] Verify 400 error with validation details
    - [x] Send create-task with invalid status: `await client.post(...)`
    - [x] Verify 400 error
  - [x] Use pytest markers: `@pytest.mark.asyncio` and `@pytest.mark.integration` for all tests
  - [x] Cleanup handled automatically by test_db fixture (deletes 'test-%' patterns)
  - [x] Run tests: `pytest tests/integration/test_task_actions.py -v`

- [x] **Task 7: Update README with Task Actions Documentation** (AC: 1-3)
  - [x] Open `task-manager-api/README.md`
  - [x] Locate \"Command Pattern Architecture\" section
  - [x] Add subsection: \"### Available Actions\"
  - [x] Document **create-task** action:
    - [x] Action name: `create-task`
    - [x] Purpose: Create a new task for user
    - [x] Payload schema: `{ title, description?, status?, priority?, due_date? }`
    - [x] Response: Created task object with id, created_at, etc.
    - [x] Example curl command
  - [x] Document **list-tasks** action:
    - [x] Action name: `list-tasks`
    - [x] Purpose: List all tasks for user with optional status filter
    - [x] Payload schema: `{ status?: string }`
    - [x] Response: `{ tasks: [...], count: number }`
    - [x] Example curl command with status filter
  - [x] Add note about TaskCreate/TaskResponse models and validation rules

- [x] **Task 8: Manual Verification** (AC: 2-7)
  - [x] Start development environment: `docker-compose -f docker-compose.dev.yml up -d`
  - [x] Test create-task via Swagger UI (http://localhost:8010/docs):
    - [x] Send POST /execute: `{\"action\": \"create-task\", \"user_id\": \"manual-test\", \"payload\": {\"title\": \"Buy milk\", \"priority\": \"high\"}}`
    - [x] Verify response has success=true and task data with id
    - [x] Verify task in database: `docker exec taskmanager-postgres-dev psql -U taskuser -d taskmanager_dev -c \"SELECT * FROM tasks WHERE user_id = 'manual-test';\"`
  - [x] Test list-tasks via Swagger UI:
    - [x] Create 3 tasks with different statuses (pending, in_progress, completed)
    - [x] Send POST /execute: `{\"action\": \"list-tasks\", \"user_id\": \"manual-test\", \"payload\": {}}`
    - [x] Verify response contains all 3 tasks
    - [x] Send with filter: `{\"payload\": {\"status\": \"pending\"}}`
    - [x] Verify response contains only pending tasks
  - [x] Test validation errors:
    - [x] Send create-task with missing title
    - [x] Verify 400 error response
    - [x] Send create-task with invalid status value
    - [x] Verify 400 error with validation details
  - [x] Check logs for structured output:
    - [x] Run: `docker logs taskmanager-api-dev --tail 50`
    - [x] Verify task creation logs include task_id and user_id
    - [x] Verify list query logs include user_id, status_filter, and count
  - [x] Clean up test data: `docker exec taskmanager-postgres-dev psql -U taskuser -d taskmanager_dev -c \"DELETE FROM tasks WHERE user_id = 'manual-test';\"`
  - [x] Document verification results in story completion notes

---

## Dev Notes

### Previous Story Context

**Story 3.2 - Command Router & Request Models Completed:**

- Command router infrastructure fully implemented with POST /execute endpoint
- `CommandRequest` and `CommandResponse` Pydantic models created
- ACTION_HANDLERS dictionary created but empty (ready for handler registration)
- Service key validation integrated via `validate_service_key` dependency
- Router returns 404 for unknown actions with error message
- Structured logging includes action, user_id, key_name in all log events
- 100% unit test coverage (15/15 passing), integration test structure created
- Command Pattern Architecture documented in README.md

**Story 3.1 - Task Schema & Migration System Completed:**

- Tasks table created with full schema (9 columns: id, user_id, title, description, status, priority, created_at, completed_at, due_date)
- Alembic migration `92389ddb0a57_create_tasks_table.py` successfully applied
- Pydantic models created in `app/models/task.py`:
  - `TaskCreate`: Request validation for create-task action
  - `TaskUpdate`: Partial update validation (used in Story 3.4)
  - `TaskResponse`: Response serialization with from_attributes for ORM compatibility
- Database indexes created: `idx_tasks_user_id` (single-column) and `idx_tasks_user_status` (composite)
- Migration system fully functional with rollback capability verified

**Story 2.1 - Database Schema & Service Key Dependency Completed:**

- `validate_service_key` dependency implemented in `app/auth.py` and fully tested
- Database connection pool configured with asyncpg (min_size=2, max_size=10)
- `get_db()` FastAPI dependency available for database operations
- asyncpg connection passed directly to handlers (no service layer in MVP)

[Source: docs/stories/3.2.story.md, docs/stories/3.1.story.md, docs/stories/2.1.story.md]

### Architecture: Handler Pattern and Signature

**Universal Handler Signature:**

All command handlers MUST follow this signature for consistent routing:

\\\python
async def handler(user_id: str, payload: dict, db) -> dict:
    \"\"\"
    Args:
        user_id: External user ID from Cat House (already authenticated)
        payload: Action-specific parameters (dict, validated by handler)
        db: asyncpg database connection from pool (dependency injection)
            Note: Type is Any in router.py, but actual runtime type is asyncpg.Connection
    
    Returns:
        dict: Response data (will be wrapped in CommandResponse by router)
    
    Raises:
        HTTPException: For validation errors (400), not found (404), etc.
    \"\"\"
    pass
\\\

**Key Principles:**

1. **user_id from Cat House:** Handler receives user_id extracted from CommandRequest (Cat House already authenticated user)
2. **payload is dict:** Handler responsible for validating payload using Pydantic models (e.g., TaskCreate)
3. **db is asyncpg connection:** Direct database access, no service layer in MVP
4. **Return dict:** Router wraps result in CommandResponse (success, data, timestamp)
5. **Raise HTTPException:** For client errors (validation, not found), router catches and returns error response

**Error Handling Pattern:**

\\\python
# Validation errors: Raise HTTPException(400)
try:
    task_data = TaskCreate(**payload)
except ValidationError as e:
    raise HTTPException(status_code=400, detail=str(e))

# Database errors: Log and raise HTTPException(500)
try:
    row = await db.fetchrow(sql, ...)
except Exception as e:
    logger.error(\"database_error\", user_id=user_id, error=str(e))
    raise HTTPException(status_code=500, detail=\"Internal server error\")

# Not found errors: Raise HTTPException(404)
if not row:
    raise HTTPException(status_code=404, detail=f\"Task not found: {task_id}\")
\\\

[Source: docs/architecture/command-pattern-architecture.md, docs/architecture/backend-architecture.md#command-routing]

### Architecture: asyncpg Database Operations

**Direct asyncpg Usage (No ORM):**

Task Manager uses asyncpg directly for database operations (no SQLAlchemy ORM). This provides high performance for simple CRUD operations.

**Common asyncpg Patterns:**

**1. INSERT with RETURNING (create_task_handler):**

\\\python
sql = \"\"\"
    INSERT INTO tasks (user_id, title, description, status, priority, due_date)
    VALUES (\, \, \, \, \, \)
    RETURNING *
\"\"\"
row = await db.fetchrow(sql, user_id, task_data.title, task_data.description, 
                         task_data.status, task_data.priority, task_data.due_date)
\\\

**Why RETURNING *:** Returns complete row with generated values (id, created_at) in single query

**2. SELECT with WHERE (list_tasks_handler):**

\\\python
# Without filter
sql = \"SELECT * FROM tasks WHERE user_id = \ ORDER BY created_at DESC\"
rows = await db.fetch(sql, user_id)

# With status filter
sql = \"SELECT * FROM tasks WHERE user_id = \ AND status = \ ORDER BY created_at DESC\"
rows = await db.fetch(sql, user_id, status_filter)
\\\

**Why ORDER BY created_at DESC:** Most recent tasks first (chronological order)

**3. Converting asyncpg Row to Pydantic:**

\\\python
# Single row (create, get)
task_response = TaskResponse.model_validate(row)
return task_response.model_dump(mode='json')

# Multiple rows (list)
tasks = [TaskResponse.model_validate(row).model_dump(mode='json') for row in rows]
return {\"tasks\": tasks, \"count\": len(tasks)}
\\\

**Why model_dump(mode='json'):** Serializes Pydantic model to JSON-compatible dict (UUID  str, datetime  ISO 8601)

**asyncpg vs SQLAlchemy:**

-  **asyncpg:** Direct SQL, high performance, simple CRUD, minimal overhead
-  **SQLAlchemy ORM:** Complex queries, relationships, migrations (not needed for MVP)

[Source: docs/architecture/backend-architecture.md#database-configuration, asyncpg documentation]

### Architecture: Pydantic Validation in Handlers

**Two-Stage Validation Pattern:**

1. **Router validates CommandRequest:** FastAPI automatically validates CommandRequest (action, user_id, payload)
2. **Handler validates payload:** Handler validates action-specific payload using Pydantic model (TaskCreate)

**Example: create_task_handler Validation:**

\\\python
async def create_task_handler(user_id: str, payload: dict, db) -> dict:
    # Stage 1: CommandRequest already validated by router (action, user_id, payload)
    # Stage 2: Validate payload using TaskCreate model
    try:
        task_data = TaskCreate(**payload)
    except ValidationError as e:
        # Return 400 with Pydantic validation errors
        raise HTTPException(status_code=400, detail=str(e))
    
    # Use validated task_data for database insertion
    # ...
\\\

**ValidationError Format:**

Pydantic ValidationError includes:
- Field name that failed validation
- Validation rule that failed (e.g., \"max_length\", \"pattern\")
- Input value that caused error

**Example Error Response:**

\\\json
{
  \"detail\": \"1 validation error for TaskCreate\\ntitle\\n  Field required [type=missing, input_value={}, input_type=dict]\"
}
\\\

**Why Validate in Handler?**

- **Flexibility:** Each action can have different payload schemas (TaskCreate, TaskUpdate, etc.)
- **Type Safety:** task_data is typed (TaskCreate) with IDE autocomplete
- **Clear Errors:** Pydantic provides detailed validation error messages
- **Decoupling:** Router doesn't need to know about action-specific models

[Source: docs/architecture/backend-architecture.md#data-model, Pydantic v2 documentation]

### Architecture: Response Format Standardization

**Handler Response Requirements:**

Handlers MUST return dict that will be wrapped in CommandResponse by router:

\\\python
# create_task_handler returns single task dict
return {
    \"id\": \"uuid\",
    \"user_id\": \"user_123\",
    \"title\": \"Buy milk\",
    # ... all task fields
}

# list_tasks_handler returns tasks array + count
return {
    \"tasks\": [
        {\"id\": \"uuid1\", \"title\": \"Task 1\", ...},
        {\"id\": \"uuid2\", \"title\": \"Task 2\", ...}
    ],
    \"count\": 2
}
\\\

**Final API Response (wrapped by router):**

\\\json
{
  \"success\": true,
  \"data\": {
    \"id\": \"uuid\",
    \"user_id\": \"user_123\",
    \"title\": \"Buy milk\"
  },
  \"error\": null,
  \"timestamp\": \"2025-11-12T10:30:00Z\"
}
\\\

**Why dict Instead of Pydantic Model?**

- **Router Responsibility:** Router wraps response in CommandResponse
- **Flexibility:** Different handlers return different structures (single object vs array)
- **JSON Serialization:** Pydantic model_dump(mode='json') converts to JSON-compatible dict

[Source: docs/stories/3.2.story.md#dev-notes-response-models]

### Architecture: Structured Logging in Handlers

**Required Log Fields:**

All handler logs MUST include:
- `action`: Implicit from handler name (e.g., \"create-task\")
- `user_id`: From handler parameter
- `task_id`: For single-task operations (get, update, delete)
- `count`: For list operations

**Logging Pattern:**

\\\python
import structlog

logger = structlog.get_logger()

# Log successful task creation
logger.info(
    \"task_created\",
    task_id=str(task_id),
    user_id=user_id,
    title=task_data.title
)

# Log successful list query
logger.info(
    \"tasks_listed\",
    user_id=user_id,
    status_filter=status_filter,
    count=len(tasks)
)

# Log database error
logger.error(
    \"database_error\",
    action=\"create-task\",
    user_id=user_id,
    error=str(e)
)
\\\

**Why Structured Logging?**

- **Machine Readable:** JSON format enables log aggregation (CloudWatch, Datadog)
- **Contextual:** Each log includes all relevant context for debugging
- **Searchable:** Easy to filter by user_id, task_id, or action
- **Performance:** structlog is designed for high-performance async applications

[Source: docs/stories/3.2.story.md#dev-notes-logging, docs/architecture/backend-architecture.md#logging]

### Architecture: Project Structure Impact

**Files Created in Story 3.3:**

\\\
task-manager-api/
 app/
    commands/
        handlers/
            tasks.py                          # NEW - Task CRUD handlers
 tests/
     unit/
        test_task_handlers.py                 # NEW - Handler unit tests
     integration/
         test_task_actions.py                  # NEW - Task action integration tests
\\\

**Files Modified in Story 3.3:**

\\\
task-manager-api/
 app/
    commands/
        router.py                             # MODIFIED - Register handlers
 README.md                                     # MODIFIED - Document actions
\\\

**Handler Registration Pattern:**

\\\python
# app/commands/router.py
from app.commands.handlers.tasks import create_task_handler, list_tasks_handler

ACTION_HANDLERS = {
    \"create-task\": create_task_handler,
    \"list-tasks\": list_tasks_handler,
    # More handlers added in Story 3.4: get-task, update-task, delete-task
}
\\\

[Source: docs/architecture/backend-architecture.md#project-structure]

### Testing Strategy

**Unit Testing Approach:**

Story 3.3 focuses on testing handler business logic in isolation from HTTP layer.

**Test File:** `tests/unit/test_task_handlers.py`

**Test Categories:**

1. **Payload Validation (AC2):**
   - Test TaskCreate validation with valid payload
   - Test missing title raises HTTPException(400)
   - Test invalid status value raises HTTPException(400)
   - Test invalid priority value raises HTTPException(400)

2. **Database Operations (AC2-3):**
   - Mock asyncpg db.fetchrow for create handler
   - Mock asyncpg db.fetch for list handler
   - Verify SQL parameters passed correctly
   - Verify RETURNING clause returns complete row

3. **Response Format (AC7):**
   - Test handler returns dict (not Pydantic model)
   - Test dict has all required fields (id, user_id, title, etc.)
   - Test list handler returns {\"tasks\": [...], \"count\": number}

**Mocking Strategy:**

\\\python
from unittest.mock import AsyncMock
import pytest

@pytest.fixture
def mock_db():
    db = AsyncMock()
    # Mock fetchrow for create handler
    db.fetchrow.return_value = {
        'id': '550e8400-e29b-41d4-a716-446655440000',
        'user_id': 'test-user',
        'title': 'Test Task',
        'description': None,
        'status': 'pending',
        'priority': None,
        'created_at': datetime.now(timezone.utc),
        'completed_at': None,
        'due_date': None
    }
    # Mock fetch for list handler
    db.fetch.return_value = [...]
    return db

@pytest.mark.unit
@pytest.mark.asyncio
async def test_create_task_handler_success(mock_db):
    payload = {\"title\": \"Test Task\", \"priority\": \"high\"}
    result = await create_task_handler(\"test-user\", payload, mock_db)
    
    assert result[\"title\"] == \"Test Task\"
    assert result[\"priority\"] == \"high\"
    assert result[\"user_id\"] == \"test-user\"
    mock_db.fetchrow.assert_called_once()
\\\

**Integration Testing Approach:**

Story 3.3 integration tests verify full request flow with real database.

**Test File:** `tests/integration/test_task_actions.py`

**Test Categories:**

1. **End-to-End Task Creation (AC2):**
   - Send POST /execute with action=\"create-task\"
   - Verify CommandResponse wrapper (success, data, timestamp)
   - Verify task created in database with correct user_id
   - Verify database-generated fields (id, created_at)

2. **End-to-End Task Listing (AC3):**
   - Create multiple test tasks with different statuses
   - Test list without filter (returns all user tasks)
   - Test list with status filter (returns only matching tasks)
   - Verify chronological order (created_at DESC)

3. **Validation Error Handling (AC2, 5):**
   - Test create with missing title returns 400
   - Test create with invalid status returns 400
   - Verify error response format (success=false, error message)

**Test Fixtures (from conftest.py):**

\\\python
# tests/integration/conftest.py
# Fixtures are now available globally for all integration tests

@pytest_asyncio.fixture(scope="function")
async def test_db():
    \"\"\"Real database connection for integration tests with automatic cleanup\"\"\"
    conn = await asyncpg.connect(
        \"postgresql://taskuser:taskpass@postgres:5432/taskmanager_dev\"
    )
    # Cleanup handled before and after each test
    await conn.execute(\"DELETE FROM tasks WHERE user_id LIKE 'test-%'\")
    yield conn
    await conn.execute(\"DELETE FROM tasks WHERE user_id LIKE 'test-%'\")
    await conn.close()

@pytest_asyncio.fixture(scope="function")
async def client():
    \"\"\"Async HTTP client for API testing\"\"\"
    await close_db_pool()  # Prevent event loop issues
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url=\"http://test\") as ac:
        yield ac
    await close_db_pool()

@pytest_asyncio.fixture(scope="function")
async def test_service_key(test_db):
    \"\"\"Create test service key for authentication\"\"\"
    key = generate_service_key('dev')
    await test_db.execute(
        \"\"\"INSERT INTO service_api_keys (key_name, api_key, environment, active) 
           VALUES ($1, $2, $3, $4)\"\"\",
        \"test-client\", key, \"dev\", True
    )
    return key
    # Cleanup handled automatically by test_db fixture
\\\

**Important Testing Notes:**

1. **All integration tests MUST use async/await:**
   - Mark tests with `@pytest.mark.asyncio` and `@pytest.mark.integration`
   - Use `async def test_name(client, test_service_key, test_db)`
   - Use `await` for HTTP requests: `response = await client.post(...)`
   - Use `await` for database queries: `row = await test_db.fetchrow(...)`

2. **Fixtures are automatically available:**
   - `client`: Async HTTP client (httpx.AsyncClient)
   - `test_service_key`: Valid service key string for X-Service-Key header
   - `test_db`: Real asyncpg connection with auto-cleanup

3. **Test data cleanup is automatic:**
   - test_db fixture deletes all data matching 'test-%' patterns
   - No need to manually clean up in tests
   - Use user_id starting with 'test-' for all test data

**Running Tests:**

\\\bash
# Unit tests only (fast, no database, uses mocks)
pytest tests/unit/test_task_handlers.py -v

# Integration tests (requires database, uses real dependencies)
pytest tests/integration/test_task_actions.py -v

# All tests with coverage
pytest tests/ --cov=app.commands.handlers.tasks --cov-report=term-missing

# Note: pytest-asyncio is required (already in requirements-dev.txt)
# Install with: pip install -r requirements-dev.txt
\\\

[Source: docs/prd/testing-strategy.md, docs/stories/3.2.story.md#dev-notes-testing]

### Important Implementation Notes

1. **TaskCreate Validation:**
   - Title is required (Field(...) enforces non-null)
   - Status has default \"pending\" (optional in payload)
   - Priority and due_date are optional (Field(None))
   - Status and priority validated via regex pattern (enum-like behavior)

2. **Database-Generated Fields:**
   - `id`: Generated by PostgreSQL `gen_random_uuid()`
   - `created_at`: Set by PostgreSQL `NOW()` default
   - `completed_at`: NULL (set in Story 3.4 when status  completed)
   - Handler does NOT provide these fields in INSERT

3. **User Scoping:**
   - ALL queries MUST filter by user_id from command
   - Prevents users from accessing other users' tasks
   - user_id provided by Cat House (already authenticated)

4. **Composite Index Usage:**
   - Query: `WHERE user_id = \ AND status = \`
   - PostgreSQL uses `idx_tasks_user_status` (optimal)
   - Query: `WHERE user_id = \` (no status filter)
   - PostgreSQL uses `idx_tasks_user_id` (smaller, faster)

5. **Error Response Format:**
   - HTTPException raised by handler
   - Router catches and returns CommandResponse with success=false
   - Cat House always receives consistent response structure

6. **Logging Best Practices:**
   - Log successful operations at INFO level
   - Log database errors at ERROR level
   - Include user_id in all logs (aids debugging)
   - Keep log messages searchable (e.g., \"task_created\" not \"Task has been created\")

7. **No completed_at Logic Yet:**
   - Story 3.3 only implements create and list
   - completed_at field is NULL for all tasks
   - Story 3.4 will implement update handler that sets completed_at when status  completed

[Source: docs/stories/3.1.story.md#dev-notes, docs/architecture/backend-architecture.md]

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-12 | 1.0 | Initial story draft with comprehensive context from Epic 3.3, command pattern architecture, handler signature, asyncpg patterns, validation strategy, testing approach, and previous stories 3.2, 3.1, 2.1 | Bob (Scrum Master) |
| 2025-11-12 | 1.1 | **Architecture Alignment Corrections:** (1) Created shared conftest.py with test_db, client, and test_service_key fixtures for integration tests, (2) Updated Task 6 to use async/await pattern consistently with existing tests, (3) Corrected handler signature type annotations to match router.py implementation, (4) Added explicit pytest-asyncio usage notes | Winston (Architect) |

---

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

Claude 3.5 Sonnet (new)

### Debug Log References

N/A - No blocking issues encountered during implementation

### Completion Notes

**Implementation Summary:**
- Created `app/commands/handlers/tasks.py` with `create_task_handler` and `list_tasks_handler`
- Both handlers registered in `ACTION_HANDLERS` dictionary in `app/commands/router.py`
- Implemented asyncpg Row to dict conversion (`dict(row)`) for Pydantic compatibility
- Added comprehensive error handling with structured logging (structlog)
- Created 10 unit tests in `tests/unit/test_task_handlers.py` - **All passing (10/10)**
- Created 10 integration tests in `tests/integration/test_task_actions.py` - **All passing (10/10)**
- Updated README.md with detailed action documentation (create-task and list-tasks)

**Test Results:**
- Unit tests: 10/10 passing (100% success rate)
- Integration tests: 10/10 passing (100% success rate)
- Full regression: 87/87 tests passing (no regressions introduced)
- All validation scenarios tested: missing title, invalid status, invalid priority

**Manual Verification Completed:**
- ✅ Created 3 tasks via POST /execute with different payloads
- ✅ Listed all tasks (returned 3 tasks with count=3)
- ✅ Listed tasks with status filter (pending: 2 tasks, completed: 1 task)
- ✅ Verified validation errors return 400 with Pydantic error details
- ✅ Verified database persistence with direct PostgreSQL queries
- ✅ Verified structured logging includes task_id, user_id, status_filter, count
- ✅ Cleaned up test data

**Key Implementation Details:**
1. **asyncpg Row Conversion:** Must convert Record to dict before Pydantic validation - `dict(row)`
2. **Datetime Serialization:** Pydantic `model_dump(mode='json')` serializes datetime as "Z" format
3. **Composite Index Usage:** Queries with `user_id + status` leverage `idx_tasks_user_status`
4. **Response Format:** Handlers return plain dict, router wraps in CommandResponse
5. **Error Handling:** ValidationError → 400, Database error → 500 with generic message

**Story Definition of Done:**
- [x] All acceptance criteria met (AC 1-7)
- [x] Code follows handler signature pattern from architecture
- [x] 100% test coverage for handlers (unit + integration)
- [x] README documentation updated with action examples
- [x] Manual verification completed successfully
- [x] No regressions in existing tests (87/87 passing)
- [x] Structured logging implemented correctly

### File List

**Created Files:**
- `app/commands/handlers/tasks.py` - Task command handlers (create, list)
- `tests/unit/test_task_handlers.py` - Unit tests for handlers (10 tests)
- `tests/integration/test_task_actions.py` - Integration tests for actions (10 tests)

**Modified Files:**
- `app/commands/router.py` - Registered create-task and list-tasks handlers
- `task-manager-api/README.md` - Added Available Actions section with documentation

---

## QA Results

### Review Date: November 12, 2025

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall Assessment: EXCELLENT**

The implementation demonstrates production-ready quality with comprehensive test coverage, proper error handling, and adherence to architectural patterns. Both handlers follow the universal handler signature perfectly and integrate seamlessly with the command router.

**Strengths:**
- Clean separation of concerns (validation → database → response transformation)
- Proper asyncpg Row to dict conversion handling
- Comprehensive error handling with descriptive logging
- 100% test coverage (20/20 tests passing - 10 unit + 10 integration)
- Excellent documentation in code comments and README
- Proper Pydantic validation with helpful error messages

**Code Architecture:**
- Handlers follow universal signature: `async def handler(user_id: str, payload: dict, db) -> dict`
- Two-stage validation pattern (CommandRequest → TaskCreate/TaskUpdate)
- Proper separation: validation → SQL execution → response serialization
- Structured logging with all required context fields

### Refactoring Performed

No refactoring required. Implementation follows all architectural patterns and coding standards correctly.

### Compliance Check

- ✅ Coding Standards: All type hints present, proper async/await usage, comprehensive docstrings
- ✅ Project Structure: Files in correct locations (app/commands/handlers/, tests/unit/, tests/integration/)
- ✅ Testing Strategy: 100% coverage with appropriate unit/integration split, proper fixtures usage
- ✅ All ACs Met: All 7 acceptance criteria fully implemented and tested

### Improvements Checklist

All items completed by development team:

- [x] Task handlers module created with create and list operations
- [x] Universal handler signature followed correctly
- [x] asyncpg Row to dict conversion handled properly
- [x] Comprehensive error handling (ValidationError → 400, Database errors → 500)
- [x] Structured logging with all context fields
- [x] 10 unit tests with proper mocking (100% pass rate)
- [x] 10 integration tests with real database (100% pass rate)
- [x] README documentation updated with action examples
- [x] Handlers registered in ACTION_HANDLERS dictionary
- [x] No regressions (87/87 full suite tests passing)

### Requirements Traceability

**AC1: Create handlers module** ✅
- Tests: All unit/integration tests import from `app.commands.handlers.tasks`
- Coverage: Module exists with proper docstring and imports

**AC2: Implement create_task_handler** ✅
- Tests: 
  - `test_create_task_handler_success` (happy path with valid payload)
  - `test_create_task_handler_with_all_fields` (all optional fields)
  - `test_create_task_handler_missing_title` (validation: 400 error)
  - `test_create_task_handler_invalid_status` (validation: 400 error)
  - `test_create_task_handler_invalid_priority` (validation: 400 error)
  - `test_create_task_handler_database_error` (error handling: 500)
  - `test_create_task_success` (integration: E2E with database)
  - `test_create_task_with_all_fields` (integration: all fields)
  - `test_create_task_missing_title` (integration: validation in API)
  - `test_create_task_invalid_status` (integration: validation in API)
  - `test_create_task_invalid_priority` (integration: validation in API)
- Coverage: All validation, database operations, error handling tested

**AC3: Implement list_tasks_handler** ✅
- Tests:
  - `test_list_tasks_handler_no_filter` (all tasks returned)
  - `test_list_tasks_handler_with_status_filter` (filtered results)
  - `test_list_tasks_handler_empty_result` (no tasks scenario)
  - `test_list_tasks_handler_database_error` (error handling: 500)
  - `test_list_tasks_no_filter` (integration: list all)
  - `test_list_tasks_with_status_filter` (integration: filtered)
  - `test_list_tasks_empty_result` (integration: empty result)
  - `test_list_tasks_user_scoping` (integration: user isolation)
  - `test_list_tasks_with_completed_status` (integration: completed filter)
- Coverage: All query variations, filters, user scoping tested

**AC4: Both handlers use asyncpg** ✅
- Tests: All integration tests verify real database operations
- Coverage: asyncpg connection usage verified via `db.fetchrow()` and `db.fetch()` calls

**AC5: Both handlers include error handling** ✅
- Tests: Database error tests for both handlers (unit + integration)
- Coverage: ValidationError → 400, Database errors → 500, with structured logging

**AC6: Register handlers in ACTION_HANDLERS** ✅
- Tests: Integration tests verify routing through `/execute` endpoint
- Coverage: Both handlers accessible via "create-task" and "list-tasks" actions

**AC7: Handlers return dict responses** ✅
- Tests: All tests verify dict structure (not Pydantic models)
- Coverage: create returns task dict, list returns {tasks: [], count: N}

### Security Review

**No Security Concerns Found**

✅ **User Scoping:** All queries filter by `user_id` from command (prevents cross-user access)  
✅ **SQL Injection Protection:** Uses parameterized queries (`$1`, `$2`) throughout  
✅ **Input Validation:** Pydantic validation prevents invalid data from reaching database  
✅ **Error Messages:** Generic error messages (500: "Internal server error") prevent information leakage  
✅ **Logging Security:** Structured logs include context for debugging without exposing sensitive data

### Performance Considerations

**Database Index Usage: OPTIMAL**

✅ **Single-column queries:** `WHERE user_id = $1` uses `idx_tasks_user_id` (fast lookup)  
✅ **Filtered queries:** `WHERE user_id = $1 AND status = $2` uses `idx_tasks_user_status` (composite index, optimal)  
✅ **Sort order:** `ORDER BY created_at DESC` provides chronological listing (no additional index needed for MVP)

**asyncpg Performance:**
- Direct asyncpg usage provides high performance (no ORM overhead)
- Connection pooling via FastAPI dependency injection
- Single-query operations (no N+1 queries)

**Recommendation:** Performance is production-ready for MVP. Consider adding pagination in future story if task lists exceed 100 items per user.

### Testing Quality

**Unit Tests: EXCELLENT (10/10 passing)**
- Comprehensive mocking strategy with AsyncMock
- All validation scenarios covered (missing title, invalid status, invalid priority)
- Database error handling tested
- Response format validation included
- Clear test names and docstrings

**Integration Tests: EXCELLENT (10/10 passing)**
- Real database operations with proper fixtures
- End-to-end request/response validation
- User scoping verification (critical security test)
- Filter functionality tested (no filter, status filter, empty results)
- Cleanup strategy prevents test pollution (test-% prefix + autouse fixture)

**No Test Gaps Identified**

### Files Modified During Review

None - no refactoring required.

### Gate Status

**Gate: PASS** → docs/qa/gates/3.3-task-command-handlers-create-list.yml

All acceptance criteria met with comprehensive test coverage and no blocking issues.

### Recommended Status

**✅ Ready for Done**

Implementation is production-ready with:
- 100% test coverage (20/20 tests passing)
- No regressions (87/87 full suite passing)
- All architectural patterns followed correctly
- Comprehensive documentation
- Security and performance validated


