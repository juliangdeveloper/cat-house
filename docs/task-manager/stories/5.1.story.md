# Story 5.1: Production Docker Image & Multi-Stage Build

---

## Status
**Draft**

**Created:** November 13, 2025  
**Assigned:** Dev Agent  

---

## Story

**As a** DevOps engineer,  
**I want** an optimized production Docker image using multi-stage builds,  
**so that** the final image is small (~150MB), secure, and production-ready.

---

## Acceptance Criteria

1. Create Dockerfile with two stages: builder (installs deps) and runtime (minimal)
2. Builder stage installs gcc and compiles Python packages
3. Runtime stage copies only compiled dependencies and application code
4. Final image runs as non-root user (appuser) for security
5. Production command uses gunicorn with uvicorn workers (2 workers for 0.25 vCPU)
6. Image successfully builds with: docker build -t task-api:latest .
7. Test image locally: docker run -p 8000:8000 --env-file .env.prod task-api:latest
8. Document build process in README.md

---

## Tasks / Subtasks

- [ ] **Task 1: Create Production Dockerfile** (AC: 1, 2, 3)
  - [ ] Create `Dockerfile` (production, not `Dockerfile.dev`) in `task-manager-api/` root
  - [ ] Builder stage: Use `python:3.12-slim` base image
  - [ ] Builder stage: Install build dependencies (gcc, libpq-dev) for compiling asyncpg
  - [ ] Builder stage: Copy `requirements.txt` only (not dev dependencies)
  - [ ] Builder stage: Install Python packages to `/root/.local` using `pip install --user`
  - [ ] Runtime stage: Use clean `python:3.12-slim` base image
  - [ ] Runtime stage: Copy compiled packages from builder stage (`/root/.local`)
  - [ ] Runtime stage: Copy application code (`app/`, `alembic/`, `alembic.ini`)
  - [ ] Runtime stage: Clean up apt cache to reduce image size

- [ ] **Task 2: Configure Non-Root User** (AC: 4)
  - [ ] Create user `appuser` with no home directory (security best practice)
  - [ ] Change ownership of `/app` directory to `appuser:appuser`
  - [ ] Switch to `appuser` before CMD instruction (USER appuser)
  - [ ] Verify user has read/execute permissions for application files

- [ ] **Task 3: Configure Production Server** (AC: 5)
  - [ ] Set CMD to run gunicorn (not uvicorn directly)
  - [ ] Configure gunicorn with uvicorn worker class: `uvicorn.workers.UvicornWorker`
  - [ ] Set worker count: 2 workers (optimal for 0.25 vCPU ECS Fargate)
  - [ ] Bind to `0.0.0.0:8000` (all interfaces for container networking)
  - [ ] Configure worker timeout: 30 seconds (prevent hung requests)
  - [ ] Configure graceful timeout: 10 seconds (clean shutdown)
  - [ ] Set worker class to async (uvicorn workers are async by default)

- [ ] **Task 4: Optimize Image Size** (AC: 1)
  - [ ] Use multi-stage build to exclude build tools from final image
  - [ ] Only copy `requirements.txt` (not `requirements-dev.txt`)
  - [ ] Remove apt package lists after installation: `rm -rf /var/lib/apt/lists/*`
  - [ ] Exclude unnecessary files: `.git`, `tests/`, `docs/`, `*.pyc`, `__pycache__`
  - [ ] Use `.dockerignore` file to prevent copying unnecessary files
  - [ ] Verify final image size: `docker images task-api:latest` (target: ~150MB)

- [ ] **Task 5: Create .dockerignore File** (AC: 1)
  - [ ] Create `.dockerignore` in `task-manager-api/` root
  - [ ] Exclude: `.git`, `.env*`, `tests/`, `docs/`, `*.pyc`, `__pycache__`, `.pytest_cache`
  - [ ] Exclude: `htmlcov/`, `.coverage`, `.mypy_cache`, `.ruff_cache`
  - [ ] Exclude development files: `docker-compose.dev.yml`, `Dockerfile.dev`, `README.md`
  - [ ] Include only essential files: `app/`, `alembic/`, `requirements.txt`, `alembic.ini`

- [ ] **Task 6: Create Production Environment Template** (AC: 7)
  - [ ] Create `.env.prod.example` in `task-manager-api/` root
  - [ ] Include all required production variables from `app/config.py`
  - [ ] Document PostgreSQL production connection string format (Neon pooler for app)
  - [ ] Document CORS origins (production: only https://cathouse.gamificator.click)
  - [ ] Set LOG_LEVEL=INFO (not DEBUG for production)
  - [ ] Set ENVIRONMENT=production
  - [ ] Document that actual `.env.prod` should NEVER be committed to git
  - [ ] Add comment about AWS Secrets Manager for production secrets

- [ ] **Task 7: Build and Test Production Image** (AC: 6, 7)
  - [ ] Build image: `docker build -t task-api:latest .`
  - [ ] Verify build completes without errors
  - [ ] Check image size: `docker images task-api:latest` (should be ~150MB)
  - [ ] Create test `.env.prod` with local development database connection
  - [ ] Run container: `docker run -p 8000:8000 --env-file .env.prod task-api:latest`
  - [ ] Test health endpoint: `curl http://localhost:8000/health`
  - [ ] Test API docs accessible: `curl http://localhost:8000/docs`
  - [ ] Verify structured logs output to stdout
  - [ ] Verify container runs as non-root user: `docker exec <container> whoami` (should be appuser)
  - [ ] Test graceful shutdown: `docker stop <container>` (should exit cleanly in <15s)

- [ ] **Task 8: Verify Gunicorn Configuration** (AC: 5)
  - [ ] Start container and check logs for gunicorn startup message
  - [ ] Verify worker count: Logs should show "Booting worker with pid: X" (2 workers)
  - [ ] Verify worker class: Logs should show uvicorn worker class
  - [ ] Test concurrent requests (simulate 2 simultaneous requests, should be handled)
  - [ ] Test worker restart on failure: Kill one worker PID, verify gunicorn spawns replacement
  - [ ] Verify request timeout: Send slow request (>30s), verify worker kills it

- [ ] **Task 9: Update README.md** (AC: 8)
  - [ ] Add "Production Deployment" section to `task-manager-api/README.md`
  - [ ] Document production Docker build command with explanation
  - [ ] Document production Docker run command with environment variables
  - [ ] Explain multi-stage build benefits (smaller image, security)
  - [ ] Explain non-root user security benefits
  - [ ] Document gunicorn configuration choices (2 workers for 0.25 vCPU)
  - [ ] Document image size optimization techniques used
  - [ ] Add section comparing development vs production Dockerfiles

- [ ] **Task 10: Validate Security Best Practices** (AC: 4)
  - [ ] Verify container runs as non-root: `docker exec <container> id` (uid=1000(appuser))
  - [ ] Verify no unnecessary packages in final image (no gcc, no build tools)
  - [ ] Verify application files owned by appuser: `docker exec <container> ls -l /app`
  - [ ] Verify no sensitive files copied (.env*, credentials)
  - [ ] Run Dockerfile linting: `docker run --rm -i hadolint/hadolint < Dockerfile`
  - [ ] Document security benefits of multi-stage builds in README

---

## Dev Notes

### Previous Story Context

**Story 4.3 - API Documentation Completed:**

Epic 4 has been fully completed with comprehensive OpenAPI documentation. All 6 command actions are documented with examples, authentication schemes are clearly defined, and the API is production-ready for Cat House Platform integration.

- 179 tests pass (including OpenAPI validation tests)
- Swagger UI and ReDoc both accessible and functional
- Service key authentication fully documented
- Error response formats documented with examples
- API Usage Guide provides complete integration examples

[Source: docs/stories/4.3.story.md]

**Development Environment:**

The development environment uses `Dockerfile.dev` with hot-reload capabilities:
- Base: `python:3.12-slim`
- Installs both `requirements.txt` and `requirements-dev.txt`
- Uses uvicorn with `--reload` flag for hot-reload
- Runs as root user (acceptable for development)
- Exposes port 8000

Production Dockerfile should be optimized for size, security, and performance (no hot-reload, no dev dependencies, no root user, multi-stage build).

[Source: task-manager-api/Dockerfile.dev]

### Architecture: Multi-Stage Docker Builds

**Multi-Stage Build Pattern:**

Multi-stage builds use multiple FROM statements in a single Dockerfile. Each FROM starts a new build stage. Only the final stage becomes the final image. This allows building with all necessary tools (gcc, compilers) but shipping without them.

**Benefits:**
1. **Smaller Images:** Build tools (gcc, make, headers) excluded from final image
2. **Security:** Fewer packages = smaller attack surface
3. **Performance:** Smaller images = faster pulls and deployments
4. **Cost:** Smaller images = lower storage and transfer costs

**Pattern Structure:**

```dockerfile
# Stage 1: Builder (has all build tools)
FROM python:3.12-slim AS builder
RUN apt-get update && apt-get install -y gcc libpq-dev
COPY requirements.txt .
RUN pip install --user -r requirements.txt

# Stage 2: Runtime (minimal, production-ready)
FROM python:3.12-slim
COPY --from=builder /root/.local /root/.local
COPY app/ /app/
USER appuser
CMD ["gunicorn", "..."]
```

**Key Concepts:**
- `AS builder` - Names the stage for reference
- `COPY --from=builder` - Copies from previous stage
- Final stage has NO build tools (gcc, make, etc.)
- `pip install --user` - Installs to `/root/.local` for easy copying

[Source: Docker best practices - https://docs.docker.com/build/building/multi-stage/]

### Architecture: Python Package Installation Strategies

**Development vs Production Installation:**

```bash
# Development (Dockerfile.dev):
pip install -r requirements.txt -r requirements-dev.txt
# Includes: pytest, ruff, mypy, coverage tools

# Production (Dockerfile):
pip install --user -r requirements.txt
# ONLY runtime dependencies: fastapi, uvicorn, asyncpg, etc.
```

**Why `pip install --user`:**

The `--user` flag installs packages to `~/.local` instead of system-wide `/usr/local`. This enables:
1. Easy copying between build stages: `COPY --from=builder /root/.local /root/.local`
2. No permission issues (doesn't require root)
3. Isolation from system Python packages

**Why NOT pip install --user in Development:**

Development Dockerfile doesn't use `--user` because:
- Hot-reload requires system-wide installation
- No multi-stage build needed (not optimizing size)
- Running as root is acceptable in development

[Source: Python packaging documentation]

### Architecture: Gunicorn vs Uvicorn in Production

**Why Gunicorn + Uvicorn Workers (Not Uvicorn Alone):**

Uvicorn is an ASGI server (runs async Python). Gunicorn is a process manager (manages multiple workers). Combining them provides production-ready features:

**Gunicorn Responsibilities:**
- Process management (spawn, kill, restart workers)
- Graceful shutdowns (finish requests before exit)
- Worker health monitoring (restart crashed workers)
- Signal handling (SIGTERM, SIGINT, SIGUSR1)
- Worker preloading (share memory across workers)

**Uvicorn Responsibilities:**
- ASGI protocol implementation (async/await support)
- HTTP/1.1 and WebSocket support
- Request parsing and response formatting
- Async I/O with asyncio event loop

**Production Command:**

```bash
gunicorn app.main:app \
  --workers 2 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 30 \
  --graceful-timeout 10
```

**Configuration Rationale:**

- `--workers 2` - Optimal for 0.25 vCPU (ECS Fargate smallest size)
  - Rule: 2-4 workers per CPU core
  - 0.25 vCPU = 1/4 core → 2 workers is maximum useful
  - More workers = context switching overhead > benefits
  
- `--worker-class uvicorn.workers.UvicornWorker` - Async FastAPI support
  - FastAPI is async framework (uses async/await)
  - Standard gunicorn workers are sync (use threads/processes)
  - Uvicorn worker class enables async request handling
  
- `--bind 0.0.0.0:8000` - Listen on all interfaces
  - Required for container networking (ECS tasks)
  - `127.0.0.1` would only accept localhost (breaks ALB health checks)
  
- `--timeout 30` - Kill workers after 30s
  - Prevents hung requests from blocking workers
  - Longer than typical API response time (<200ms target)
  - Shorter than ALB timeout (60s default)
  
- `--graceful-timeout 10` - Wait 10s for clean shutdown
  - Allows in-flight requests to complete before exit
  - Critical for zero-downtime deployments (ECS rolling updates)
  - Workers receive SIGTERM → finish requests → exit

**Development vs Production:**

| Feature | Development (uvicorn) | Production (gunicorn + uvicorn) |
|---------|----------------------|----------------------------------|
| Command | `uvicorn app.main:app --reload` | `gunicorn app.main:app --workers 2 --worker-class uvicorn.workers.UvicornWorker` |
| Workers | 1 (single process) | 2 (multiple processes) |
| Hot-reload | Yes (`--reload`) | No (reload breaks worker management) |
| Worker restart | Manual (developer restarts) | Automatic (gunicorn restarts crashed workers) |
| Graceful shutdown | No | Yes (10s grace period) |
| Process management | None | Full (gunicorn master process) |

[Source: FastAPI deployment docs - https://fastapi.tiangolo.com/deployment/server-workers/]

### Architecture: Docker Security - Non-Root Users

**Why Run Containers as Non-Root:**

Container root user = Host root user (UID 0). If container is compromised:
- Root container can write to host filesystem (via volume mounts)
- Root container can escape to host (kernel exploits)
- Root container can access host processes

**Security Benefits of Non-Root:**

1. **Principle of Least Privilege:** Application only needs read/execute, not root powers
2. **Defense in Depth:** Even if container is compromised, attacker has limited privileges
3. **File System Protection:** Non-root user can't modify system files
4. **Compliance:** Many security standards require non-root containers (PCI-DSS, SOC 2)

**Implementation Pattern:**

```dockerfile
# Create user without home directory (no unnecessary files)
RUN useradd --create-home --shell /bin/bash appuser

# Change ownership of application files
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# All subsequent commands run as appuser
CMD ["gunicorn", "app.main:app", ...]
```

**Key Points:**
- User created with UID 1000 (first non-system user ID)
- Application files owned by appuser (read/write/execute)
- System files owned by root (read-only for appuser)
- No sudo or privilege escalation

**Verification:**

```bash
# Check user inside container
docker exec <container> whoami
# Output: appuser

# Check user ID
docker exec <container> id
# Output: uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)

# Check file ownership
docker exec <container> ls -l /app
# Output: drwxr-xr-x appuser appuser ...
```

[Source: Docker security best practices - https://docs.docker.com/develop/security-best-practices/]

### Architecture: Docker Image Optimization

**Image Size Optimization Techniques:**

**1. Multi-Stage Builds (Biggest Impact):**
- Builder stage: 600MB+ (includes gcc, make, headers, build artifacts)
- Runtime stage: ~150MB (only Python + compiled packages + app code)
- Savings: ~450MB (75% reduction)

**2. .dockerignore File:**
Excludes unnecessary files from build context:
- Tests: `tests/`, `pytest.ini`, `.pytest_cache/`
- Docs: `docs/`, `README.md`
- Dev files: `.env*`, `docker-compose.*.yml`, `Dockerfile.dev`
- Cache: `__pycache__/`, `*.pyc`, `.mypy_cache/`, `.ruff_cache/`
- VCS: `.git/`, `.gitignore`

**3. Minimal Base Image:**
- `python:3.12-slim` instead of `python:3.12`
- Slim variant: ~150MB (Debian minimal)
- Full variant: ~900MB (includes dev tools, docs, man pages)
- Alpine: Not recommended (musl libc breaks some Python packages)

**4. Clean Up Package Lists:**
```dockerfile
RUN apt-get update && apt-get install -y gcc libpq-dev \
    && rm -rf /var/lib/apt/lists/*
```
- `/var/lib/apt/lists/*` contains package index (30-50MB)
- Only needed during `apt-get install`
- Safe to delete after installation

**5. Layer Caching Strategy:**
```dockerfile
# Copy requirements first (changes infrequently)
COPY requirements.txt .
RUN pip install --user -r requirements.txt

# Copy app code last (changes frequently)
COPY app/ /app/
```
- Docker caches each layer (RUN, COPY, etc.)
- Changing line X invalidates cache for X and all subsequent lines
- requirements.txt changes less often than app code
- Result: Faster rebuilds (skip pip install if requirements unchanged)

**Target Image Size Breakdown:**
- Base image (python:3.12-slim): ~150MB
- Python packages (FastAPI, asyncpg, etc.): ~50MB
- Application code: <5MB
- **Total: ~200MB** (target: ~150MB with aggressive optimization)

**Size Verification:**

```bash
# Check image size
docker images task-api:latest

# Compare with development image
docker images taskmanager-api-dev

# Inspect layers
docker history task-api:latest
```

[Source: Docker image optimization guide]

### Architecture: Production Environment Variables

**Required Production Environment Variables:**

From `app/config.py` Settings class (Pydantic validation):

**Database Configuration:**
```bash
# Neon PostgreSQL production connection
DATABASE_URL=postgresql+asyncpg://user:pass@project-pooler.neon.tech:5432/taskmanager_prod?sslmode=require
# Use pooler URL (-pooler.neon.tech) for connection pooling
# Use asyncpg driver for async support
# Use sslmode=require for encrypted connection

# Alembic migrations (direct connection, not pooler)
MIGRATION_DATABASE_URL=postgresql://user:pass@project.neon.tech:5432/taskmanager_prod?sslmode=require
```

**Application Configuration:**
```bash
ENVIRONMENT=production
LOG_LEVEL=INFO  # Not DEBUG (too verbose in production)
PORT=8000  # Internal container port
```

**CORS Configuration:**
```bash
# CRITICAL: ONLY Cat House production domain
CORS_ORIGINS=https://cathouse.gamificator.click
# DO NOT use wildcard (*) or http:// in production
# DO NOT include localhost origins in production
```

**Authentication Configuration:**
```bash
# Service API Key generation secret (32+ characters)
API_KEY_SECRET=<generate-secure-random-string-32-chars-min>

# Admin endpoint protection (rotate regularly)
ADMIN_API_KEY=<generate-secure-random-admin-key>
```

**Production Secrets Management:**

**Local Testing:**
- Use `.env.prod` file (git-ignored)
- Copy from `.env.prod.example` template
- Manually set values for local production testing

**AWS Production Deployment:**
- Use AWS Secrets Manager (Story 5.2)
- ECS task pulls secrets at runtime
- Secrets injected as environment variables
- NEVER commit `.env.prod` to git
- NEVER hardcode secrets in Dockerfile

**Validation:**

Application validates all required variables on startup (fail-fast):
```python
# app/config.py
class Settings(BaseSettings):
    database_url: str  # Required (no default)
    environment: str = "development"  # Has default
    
    @validator('database_url')
    def validate_database_url(cls, v):
        if not v.startswith('postgresql'):
            raise ValueError('Must be PostgreSQL connection string')
        return v
```

If DATABASE_URL is missing or invalid, application exits immediately with clear error.

[Source: app/config.py, docs/architecture/backend-architecture.md]

### Architecture: Docker vs Docker Compose

**Dockerfile vs docker-compose.yml:**

- **Dockerfile:** Defines HOW to build an image (instructions)
- **docker-compose.yml:** Defines HOW to run containers (orchestration)

**This Story (5.1) Creates:**
- `Dockerfile` - Production image build instructions
- NOT `docker-compose.yml` - Development orchestration already exists

**When to Use Each:**

**Use Dockerfile:**
- Building images for deployment (AWS ECS, Kubernetes, etc.)
- CI/CD pipelines (GitHub Actions builds and pushes)
- Production deployments (single container from image)

**Use docker-compose.yml:**
- Local development (multiple services: API + PostgreSQL)
- Integration testing (spin up test environment)
- Team development (consistent local setup)

**This Project Has:**
- `Dockerfile.dev` - Development image (hot-reload, dev dependencies)
- `docker-compose.dev.yml` - Development orchestration (API + PostgreSQL)
- `Dockerfile` - Production image (optimized, secure, gunicorn) [Created in this story]
- NO `docker-compose.yml` for production (AWS ECS handles orchestration)

**Production Deployment Pattern:**
```bash
# Local: Build image
docker build -t task-api:latest .

# Local: Test image
docker run -p 8000:8000 --env-file .env.prod task-api:latest

# CI/CD: Build and push
docker build -t <ecr-repo>/task-api:$GIT_SHA .
docker push <ecr-repo>/task-api:$GIT_SHA

# AWS ECS: Pull and run
# ECS task definition references ECR image
# ECS service runs task on Fargate
```

[Source: Docker documentation]

---

## Dev Notes: Testing

### Testing Standards

**Testing Approach for Infrastructure Changes:**

Story 5.1 focuses on **Docker infrastructure** (Dockerfile, build process, container configuration). This type of change is primarily validated through **manual verification** rather than automated tests.

**Why Manual Testing:**

1. **Docker Build Process:** Testing requires actually building images and running containers
2. **Image Size:** Verification requires inspecting built images (`docker images`)
3. **Security Configuration:** Requires exec into running containers (`docker exec whoami`)
4. **Gunicorn Workers:** Requires observing startup logs and process behavior
5. **Non-Functional Requirements:** Image size, security, performance are measured, not asserted

**Manual Verification Checklist:**

- [ ] Image builds successfully: `docker build -t task-api:latest .`
- [ ] Image size is ~150MB: `docker images task-api:latest`
- [ ] Container starts successfully: `docker run -p 8000:8000 --env-file .env.prod task-api:latest`
- [ ] Health endpoint responds: `curl http://localhost:8000/health`
- [ ] Container runs as non-root: `docker exec <container> whoami` → appuser
- [ ] Gunicorn starts with 2 workers: Check logs for "Booting worker with pid: X" (appears twice)
- [ ] Graceful shutdown works: `docker stop <container>` completes in <15s
- [ ] Logs are structured JSON: Check stdout for JSON formatted logs

**Automated Tests:**

No new automated tests required for this story. Existing test suite (179 tests) validates application logic, which remains unchanged. Docker configuration does not require pytest tests.

**Integration Validation:**

Story 5.2 (AWS Infrastructure) will include integration testing where production image is deployed to ECS and tested via ALB health checks.

[Source: docs/prd/testing-strategy.md#manual-verification-checklist]

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-13 | 1.0 | Initial story draft for Epic 5.1 with comprehensive context from completed Epic 4, development Dockerfile, backend architecture, and multi-stage build best practices. Story focuses on creating production-optimized Docker image with security hardening (non-root user), size optimization (multi-stage build), and production server configuration (gunicorn + uvicorn workers). | Bob (Scrum Master - Claude Sonnet 4.5) |

---
