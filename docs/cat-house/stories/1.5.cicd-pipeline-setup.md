# Story 1.5: CI/CD Pipeline Setup

**Status:** Draft  
**Epic:** EPIC-1 - Core Platform Infrastructure  
**Created:** November 30, 2025

---

## Story

**As a** platform architect,  
**I want** to set up automated CI/CD pipelines for backend and frontend,  
**so that** code changes are automatically tested, built, and deployed to staging and production environments.

---

## Acceptance Criteria

1. **Services production-ready before deployment**
   - Structured JSON logging configured in all services
   - Correlation IDs (X-Trace-ID) implemented via middleware
   - CloudWatch log groups and retention policies defined
   - Environment-based configuration (dev uses colored logs, prod uses JSON)
   - Request/response logging with trace propagation

2. **Infrastructure as Code prerequisites**
   - Terraform modules for AWS ECR repositories (5 services)
   - Terraform for ECS Fargate cluster and task definitions
   - Terraform for S3 + CloudFront frontend hosting
   - ECS task definitions with CloudWatch log driver configured
   - All infrastructure changes version controlled

3. **GitHub Actions workflows created**
   - Backend service CI workflow (test, lint, build)
   - Frontend CI workflow (test, lint, build)
   - Docker image build and push workflow
   - Deployment workflow for staging
   - Deployment workflow for production (manual approval)

4. **Automated testing in CI**
   - Unit tests run on every push/PR (against Neon test database)
   - Integration tests run on PR to main
   - Code coverage reporting (Codecov)
   - Tests must pass before merge
   - Linting enforced (black, pylint, mypy for Python)

5. **Docker image builds automated**
   - Production-optimized Dockerfiles for all 5 services
  - Images built: auth-service, catalog-service, installation-service, proxy-service, health-aggregator
   - Images tagged with git SHA and branch
   - Images pushed to AWS ECR
   - Multi-stage builds for size optimization

6. **Deployment automation configured**
   - All 5 backend services deploy to AWS ECS Fargate
   - Frontend deploys to S3 + CloudFront (static export)
   - Database migrations run automatically (via auth-service task)
   - Health checks verify deployment success
   - Automatic rollback on failed health checks

7. **Environment management**
   - Separate workflows for staging/prod
   - Environment-specific secrets in GitHub Secrets
   - Neon database URLs per environment
   - Production deployment requires manual approval
   - Configuration validated before deployment

---

## Tasks / Subtasks

- [ ] Make services production-ready (AC: 1) **PREREQUISITE**
  - [ ] Update Loguru config to JSON format for production
  - [ ] Add correlation ID middleware to all 5 services
  - [ ] Add request/response logging middleware
  - [ ] Configure environment-based logging (JSON in prod, colored in dev)
  - [ ] Test logging output format in both environments

- [ ] Create infrastructure as code (AC: 2) **PREREQUISITE**
  - [ ] Terraform module for ECR repositories (5 repos)
  - [ ] Terraform for ECS Fargate cluster
  - [ ] Terraform for ECS task definitions (with CloudWatch log config)
  - [ ] Terraform for ECS services and load balancers
  - [ ] Terraform for S3 bucket + CloudFront distribution
  - [ ] Test infrastructure deployment to staging

- [ ] Create backend CI workflow (AC: 3, 4)
  - [ ] Set up workflow file for Python services
  - [ ] Configure test execution with Neon test database
  - [ ] Add linting (black, pylint, mypy)
  - [ ] Set up code coverage reporting (Codecov)
  - [ ] Test workflow on PR

- [ ] Create frontend CI workflow (AC: 3, 4)
  - [ ] Set up workflow file for Expo app
  - [ ] Configure test execution (Jest)
  - [ ] Add linting (ESLint) and type-check (tsc)
  - [ ] Build static export (Expo web export)
  - [ ] Test workflow on PR

- [ ] Configure Docker image builds (AC: 5)
  - [ ] Create production Dockerfiles (multi-stage)
  - [ ] Set up Docker build workflow for 5 services
  - [ ] Configure AWS ECR push
  - [ ] Implement image tagging strategy (SHA + latest)
  - [ ] Test builds for all services

- [ ] Set up backend deployment (AC: 6)
  - [ ] Configure deployment workflow for staging
  - [ ] Add database migration task (auth-service)
  - [ ] Deploy all 5 services to ECS
  - [ ] Add health check verification step
  - [ ] Implement automatic rollback on failure

- [ ] Set up frontend deployment (AC: 6)
  - [ ] Configure S3 sync workflow
  - [ ] Add CloudFront cache invalidation
  - [ ] Test static export deployment
  - [ ] Verify CORS and domain configuration

- [ ] Configure environments and secrets (AC: 7)
  - [ ] Set up GitHub environments (staging, prod)
  - [ ] Add AWS credentials as secrets
  - [ ] Add Neon database URLs as secrets
  - [ ] Configure production approval requirements
  - [ ] Test secret access in workflows

---

## Dev Notes

### Implementation Order

1. **Production-Ready Logging** (must complete first)
2. **Infrastructure as Code** (Terraform for ECR, ECS, S3/CloudFront)
3. **CI Workflows** (testing and building)
4. **CD Workflows** (deployment)

### Current Services Overview

```
cat-house-backend/
├── auth-service/         (Port 8005) - Handles Alembic migrations
├── catalog-service/      (Port 8002)
├── installation-service/ (Port 8003)
├── proxy-service/        (Port 8004)
└── health-aggregator/    (Port 8000) - Aggregates health checks

frontend/                 - React Native (Expo) universal app
├── Dockerfile.build      - Production static export
└── docker-compose.yml    - Development environment
```

### Database

- **Neon PostgreSQL** (serverless) - shared across all services
- **Migrations:** Centralized in auth-service only (Alembic)
- **Connection pooling:** 10 total connections across services
- **CI testing:** Uses Neon test database (no local Postgres)

### GitHub Actions Workflow Structure

```
.github/
└── workflows/
    ├── backend-ci.yml          # Test & lint backend
    ├── frontend-ci.yml         # Test & lint frontend
    ├── build-images.yml        # Build Docker images
    ├── deploy-staging.yml      # Deploy to staging
    └── deploy-production.yml   # Deploy to production
```

### Step 1: Production-Ready Logging Configuration

**Update Loguru Configuration (All Services):**

```python
# cat-house-backend/{service}/app/logging_config.py
from loguru import logger
import sys
import json
from contextvars import ContextVar
from app.config import settings

# Context variable for trace ID
trace_id_var: ContextVar[str] = ContextVar('trace_id', default='')

def serialize_log(record):
    """Serialize log record to JSON for CloudWatch."""
    subset = {
        "timestamp": record["time"].isoformat(),
        "level": record["level"].name,
        "service": settings.SERVICE_NAME,  # e.g., "auth-service"
        "trace_id": trace_id_var.get(),
        "message": record["message"],
        "function": record["function"],
        "line": record["line"],
        "extra": record["extra"],
    }
    return json.dumps(subset)

def patched_serialize(text):
    """Patch function to include trace_id in all logs."""
    record = json.loads(text)
    record["trace_id"] = trace_id_var.get()
    return json.dumps(record)

def setup_logging():
    """Configure logging based on environment."""
    logger.remove()  # Remove default handler
    
    if settings.ENVIRONMENT == "development":
        # Development: Colored output to stdout
        logger.add(
            sys.stdout,
            level="DEBUG",
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | <level>{message}</level>",
            colorize=True
        )
    else:
        # Production: JSON output to stdout (CloudWatch)
        logger.add(
            sys.stdout,
            level="INFO",
            serialize=True,
            format=serialize_log
        )
    
    logger.info(f"Logging configured for environment: {settings.ENVIRONMENT}")

# Export configured logger
__all__ = ["logger", "trace_id_var", "setup_logging"]
```

**Add Correlation ID Middleware:**

```python
# cat-house-backend/{service}/app/middleware.py
from fastapi import Request
from uuid import uuid4
import time
from app.logging_config import logger, trace_id_var

async def correlation_id_middleware(request: Request, call_next):
    """Add correlation ID to all requests for distributed tracing."""
    # Get or generate trace ID
    trace_id = request.headers.get("X-Trace-ID", str(uuid4()))
    trace_id_var.set(trace_id)
    
    # Log request
    start_time = time.time()
    logger.info(
        f"Request started: {request.method} {request.url.path}",
        extra={
            "method": request.method,
            "path": request.url.path,
            "client_ip": request.client.host,
            "user_agent": request.headers.get("user-agent"),
        }
    )
    
    # Process request
    response = await call_next(request)
    
    # Add trace ID to response headers
    response.headers["X-Trace-ID"] = trace_id
    
    # Log response
    duration = time.time() - start_time
    logger.info(
        f"Request completed: {response.status_code}",
        extra={
            "status_code": response.status_code,
            "duration_ms": round(duration * 1000, 2),
        }
    )
    
    return response
```

**Update main.py to use middleware:**

```python
# cat-house-backend/{service}/app/main.py
from fastapi import FastAPI
from app.logging_config import setup_logging
from app.middleware import correlation_id_middleware

# Setup logging on startup
setup_logging()

app = FastAPI(title="Auth Service")

# Add correlation ID middleware
app.middleware("http")(correlation_id_middleware)

# ... rest of app configuration
```

**Update config.py:**

```python
# cat-house-backend/{service}/app/config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    SERVICE_NAME: str = "auth-service"  # Update per service
    ENVIRONMENT: str = "development"  # development, staging, production
    # ... rest of config

settings = Settings()
```

### Step 2: Backend CI Workflow

```yaml
# .github/workflows/backend-ci.yml
name: Backend CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'cat-house-backend/**'
      - '.github/workflows/backend-ci.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'cat-house-backend/**'

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth-service, catalog-service, installation-service, proxy-service, health-aggregator]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'cat-house-backend/${{ matrix.service }}/requirements.txt'
    
    - name: Install dependencies
      working-directory: cat-house-backend/${{ matrix.service }}
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio black pylint mypy httpx
    
    - name: Run linting
      working-directory: cat-house-backend/${{ matrix.service }}
      run: |
        black --check app/
        pylint app/ --disable=C0114,C0115,C0116
        mypy app/ --ignore-missing-imports
    
    - name: Run tests
      working-directory: cat-house-backend/${{ matrix.service }}
      env:
        DATABASE_URL: ${{ secrets.NEON_TEST_DATABASE_URL }}
        ENVIRONMENT: test
      run: |
        pytest tests/ --cov=app --cov-report=xml --cov-report=term
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./cat-house-backend/${{ matrix.service }}/coverage.xml
        flags: ${{ matrix.service }}
        name: ${{ matrix.service }}-coverage
```

### Step 3: Frontend CI Workflow

```yaml
# .github/workflows/frontend-ci.yml
name: Frontend CI (Expo)

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'frontend/**'
      - '.github/workflows/frontend-ci.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'frontend/**'

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: frontend
      run: npm ci
    
    - name: Run type checking
      working-directory: frontend
      run: npm run type-check
    
    - name: Run tests
      working-directory: frontend
      run: npm run test:coverage
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/coverage-final.json
        flags: frontend
        name: frontend-coverage
    
    - name: Build web static export
      working-directory: frontend
      env:
        EXPO_PUBLIC_API_URL: https://chapi.gamificator.click
      run: |
        npx expo export --platform web
```

### Step 4: Terraform for Infrastructure

**Create ECR Repositories:**

```hcl
# cat-house-backend/terraform/ecr.tf
resource "aws_ecr_repository" "services" {
  for_each = toset([
    "auth-service",
    "catalog-service",
    "installation-service",
    "proxy-service",
    "health-aggregator"
  ])

  name                 = "cat-house/${each.key}"
  image_tag_mutability = "MUTABLE"

  image_scanning_configuration {
    scan_on_push = true
  }

  encryption_configuration {
    encryption_type = "AES256"
  }

  lifecycle_policy {
    policy = jsonencode({
      rules = [{
        rulePriority = 1
        description  = "Keep last 10 images"
        selection = {
          tagStatus   = "any"
          countType   = "imageCountMoreThan"
          countNumber = 10
        }
        action = {
          type = "expire"
        }
      }]
    })
  }

  tags = {
    Environment = var.environment
    Service     = each.key
  }
}

output "ecr_repository_urls" {
  value = {
    for k, v in aws_ecr_repository.services : k => v.repository_url
  }
}
```

**Create ECS Cluster and CloudWatch Logs:**

```hcl
# cat-house-backend/terraform/ecs.tf
resource "aws_ecs_cluster" "main" {
  name = "cat-house-${var.environment}"

  setting {
    name  = "containerInsights"
    value = "enabled"
  }

  tags = {
    Environment = var.environment
  }
}

# CloudWatch Log Groups for each service
resource "aws_cloudwatch_log_group" "services" {
  for_each = toset([
    "auth-service",
    "catalog-service",
    "installation-service",
    "proxy-service",
    "health-aggregator"
  ])

  name              = "/ecs/cat-house/${var.environment}/${each.key}"
  retention_in_days = var.environment == "production" ? 90 : 30

  tags = {
    Environment = var.environment
    Service     = each.key
  }
}
```

**Create ECS Task Definitions:**

```hcl
# cat-house-backend/terraform/ecs_tasks.tf
locals {
  services = {
    auth-service = {
      port = 8005
      cpu  = 256
      memory = 512
    }
    catalog-service = {
      port = 8002
      cpu  = 256
      memory = 512
    }
    installation-service = {
      port = 8003
      cpu  = 256
      memory = 512
    }
    proxy-service = {
      port = 8004
      cpu  = 256
      memory = 512
    }
    health-aggregator = {
      port = 8000
      cpu  = 256
      memory = 512
    }
  }
}

resource "aws_ecs_task_definition" "services" {
  for_each = local.services

  family                   = "cat-house-${var.environment}-${each.key}"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = each.value.cpu
  memory                   = each.value.memory
  execution_role_arn       = aws_iam_role.ecs_execution_role.arn
  task_role_arn            = aws_iam_role.ecs_task_role.arn

  container_definitions = jsonencode([{
    name  = each.key
    image = "${aws_ecr_repository.services[each.key].repository_url}:latest"
    
    portMappings = [{
      containerPort = each.value.port
      protocol      = "tcp"
    }]

    environment = [
      {
        name  = "ENVIRONMENT"
        value = var.environment
      },
      {
        name  = "SERVICE_NAME"
        value = each.key
      }
    ]

    secrets = [
      {
        name      = "DATABASE_URL"
        valueFrom = aws_secretsmanager_secret.database_url.arn
      }
    ]

    logConfiguration = {
      logDriver = "awslogs"
      options = {
        "awslogs-group"         = aws_cloudwatch_log_group.services[each.key].name
        "awslogs-region"        = var.aws_region
        "awslogs-stream-prefix" = "ecs"
      }
    }

    healthCheck = {
      command     = ["CMD-SHELL", "curl -f http://localhost:${each.value.port}/api/v1/${replace(each.key, "-service", "")}/health || exit 1"]
      interval    = 30
      timeout     = 5
      retries     = 3
      startPeriod = 60
    }
  }])

  tags = {
    Environment = var.environment
    Service     = each.key
  }
}
```

**Create S3 + CloudFront for Frontend:**

```hcl
# cat-house-backend/terraform/frontend.tf
resource "aws_s3_bucket" "frontend" {
  bucket = "cat-house-frontend-${var.environment}"

  tags = {
    Environment = var.environment
  }
}

resource "aws_s3_bucket_public_access_block" "frontend" {
  bucket = aws_s3_bucket.frontend.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

resource "aws_s3_bucket_website_configuration" "frontend" {
  bucket = aws_s3_bucket.frontend.id

  index_document {
    suffix = "index.html"
  }

  error_document {
    key = "index.html"
  }
}

resource "aws_cloudfront_distribution" "frontend" {
  enabled             = true
  default_root_object = "index.html"
  price_class         = "PriceClass_100"

  origin {
    domain_name = aws_s3_bucket.frontend.bucket_regional_domain_name
    origin_id   = "S3-${aws_s3_bucket.frontend.id}"

    s3_origin_config {
      origin_access_identity = aws_cloudfront_origin_access_identity.frontend.cloudfront_access_identity_path
    }
  }

  default_cache_behavior {
    allowed_methods        = ["GET", "HEAD", "OPTIONS"]
    cached_methods         = ["GET", "HEAD"]
    target_origin_id       = "S3-${aws_s3_bucket.frontend.id}"
    viewer_protocol_policy = "redirect-to-https"

    forwarded_values {
      query_string = false
      cookies {
        forward = "none"
      }
    }

    min_ttl     = 0
    default_ttl = 3600
    max_ttl     = 86400
  }

  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }

  viewer_certificate {
    cloudfront_default_certificate = true
  }

  custom_error_response {
    error_code         = 404
    response_code      = 200
    response_page_path = "/index.html"
  }

  tags = {
    Environment = var.environment
  }
}

output "cloudfront_distribution_id" {
  value = aws_cloudfront_distribution.frontend.id
}

output "cloudfront_domain_name" {
  value = aws_cloudfront_distribution.frontend.domain_name
}
```

### Step 5: Docker Build Workflow

```yaml
# .github/workflows/build-images.yml
name: Build Docker Images

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'cat-house-backend/**'
  workflow_dispatch:

env:
  AWS_REGION: us-east-1

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth-service, catalog-service, installation-service, proxy-service, health-aggregator]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    - name: Build and push image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build \
          -t $ECR_REGISTRY/cat-house/${{ matrix.service }}:$IMAGE_TAG \
          -t $ECR_REGISTRY/cat-house/${{ matrix.service }}:latest \
          -f cat-house-backend/${{ matrix.service }}/Dockerfile \
          cat-house-backend/${{ matrix.service }}
        
        docker push $ECR_REGISTRY/cat-house/${{ matrix.service }}:$IMAGE_TAG
        docker push $ECR_REGISTRY/cat-house/${{ matrix.service }}:latest
```

### Step 6: Deploy to Staging Workflow

```yaml
# .github/workflows/deploy-staging.yml
name: Deploy to Staging

on:
  push:
    branches: [ develop ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ENVIRONMENT: staging

jobs:
  # Run database migrations first (auth-service only)
  migrate:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Run database migrations
      run: |
        # Run Alembic migrations via ECS task
        TASK_ARN=$(aws ecs run-task \
          --cluster cat-house-staging \
          --task-definition cat-house-staging-migration \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}" \
          --overrides '{"containerOverrides":[{"name":"migration","command":["alembic","upgrade","head"]}]}' \
          --query 'tasks[0].taskArn' \
          --output text)
        
        echo "Waiting for migration task to complete..."
        aws ecs wait tasks-stopped --cluster cat-house-staging --tasks $TASK_ARN
        
        # Check if task succeeded
        EXIT_CODE=$(aws ecs describe-tasks \
          --cluster cat-house-staging \
          --tasks $TASK_ARN \
          --query 'tasks[0].containers[0].exitCode' \
          --output text)
        
        if [ "$EXIT_CODE" != "0" ]; then
          echo "Migration failed with exit code $EXIT_CODE"
          exit 1
        fi
        
        echo "Migration completed successfully"

  # Deploy all backend services
  deploy-backend:
    needs: migrate
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth-service, catalog-service, installation-service, proxy-service, health-aggregator]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Update ECS service
      run: |
        aws ecs update-service \
          --cluster cat-house-staging \
          --service cat-house-staging-${{ matrix.service }} \
          --force-new-deployment
    
    - name: Wait for deployment
      run: |
        echo "Waiting for service to become stable..."
        aws ecs wait services-stable \
          --cluster cat-house-staging \
          --services cat-house-staging-${{ matrix.service }}
    
    - name: Verify health check
      run: |
        # Extract service name without -service suffix for health endpoint
        SERVICE_NAME=$(echo "${{ matrix.service }}" | sed 's/-service$//')
        
        # Wait a bit for service to be fully ready
        sleep 10
        
        # Health aggregator has different endpoint
        if [ "${{ matrix.service }}" == "health-aggregator" ]; then
          HEALTH_URL="https://api-staging.gamificator.click/api/v1/health"
        else
          HEALTH_URL="https://api-staging.gamificator.click/api/v1/${SERVICE_NAME}/health"
        fi
        
        echo "Checking health at: $HEALTH_URL"
        
        # Retry health check up to 5 times
        for i in {1..5}; do
          if curl -f -s "$HEALTH_URL"; then
            echo "Health check passed"
            exit 0
          fi
          echo "Health check failed, retrying ($i/5)..."
          sleep 10
        done
        
        echo "Health check failed after 5 attempts"
        exit 1

  # Deploy frontend
  deploy-frontend:
    needs: deploy-backend
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Build frontend static export
      working-directory: frontend
      env:
        EXPO_PUBLIC_API_URL: https://api-staging.gamificator.click
      run: |
        npm ci
        npx expo export --platform web
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Sync to S3
      run: |
        aws s3 sync frontend/dist/ s3://cat-house-frontend-staging --delete
    
    - name: Invalidate CloudFront cache
      run: |
        aws cloudfront create-invalidation \
          --distribution-id ${{ secrets.CLOUDFRONT_STAGING_ID }} \
          --paths "/*"
        
        echo "Frontend deployed successfully to CloudFront"
```

### Deploy to Production Workflow

```yaml
# .github/workflows/deploy-production.yml
name: Deploy to Production

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to deploy'
        required: true

env:
  AWS_REGION: us-east-1
  ENVIRONMENT: production

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://gamificator.click
    
    steps:
    # Similar to staging but with production environment
    # Requires manual approval in GitHub
```

### Step 7: Production Dockerfiles

Create optimized production Dockerfiles for each service:

```dockerfile
# cat-house-backend/{service}/Dockerfile
# Multi-stage build for production
FROM python:3.11-slim as builder

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Production stage
FROM python:3.11-slim

WORKDIR /app

# Copy dependencies from builder
COPY --from=builder /root/.local /root/.local

# Copy application code
COPY app/ ./app/

# Make sure scripts in .local are usable
ENV PATH=/root/.local/bin:$PATH

# Non-root user for security
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8005  # Change per service: auth-service=8005, catalog-service=8002, etc.

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8005"]
```

### GitHub Secrets Required

```bash
# AWS Credentials
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY

# Neon Database URLs
NEON_TEST_DATABASE_URL          # For CI testing
NEON_STAGING_DATABASE_URL       # Staging environment
NEON_PRODUCTION_DATABASE_URL    # Production environment

# CloudFront Distribution IDs
CLOUDFRONT_STAGING_ID
CLOUDFRONT_PRODUCTION_ID

# Codecov (optional)
CODECOV_TOKEN
```

### AWS Secrets Manager Setup

```bash
# Store database URL in AWS Secrets Manager
aws secretsmanager create-secret \
  --name cat-house/staging/database-url \
  --secret-string "postgresql://user:pass@ep-xxx.us-east-1.aws.neon.tech/neondb"

aws secretsmanager create-secret \
  --name cat-house/production/database-url \
  --secret-string "postgresql://user:pass@ep-xxx.us-east-1.aws.neon.tech/neondb"
```

### Testing Checklist

- [ ] **Logging Configuration**
  - [ ] Verify JSON logs in production mode
  - [ ] Verify colored logs in development mode
  - [ ] Test correlation ID generation and propagation
  - [ ] Check logs appear in CloudWatch

- [ ] **Infrastructure**
  - [ ] Deploy Terraform to create ECR repositories
  - [ ] Deploy Terraform to create ECS cluster
  - [ ] Deploy Terraform to create S3 + CloudFront
  - [ ] Verify CloudWatch log groups created

- [ ] **CI Workflows**
  - [ ] Test backend-ci.yml on PR
  - [ ] Test frontend-ci.yml on PR
  - [ ] Verify all tests pass
  - [ ] Verify linting catches errors
  - [ ] Check code coverage reporting

- [ ] **Docker Builds**
  - [ ] Build all 5 production images locally
  - [ ] Test build-images.yml workflow
  - [ ] Verify images pushed to ECR
  - [ ] Check image sizes are optimized

- [ ] **Deployment**
  - [ ] Test migration task runs successfully
  - [ ] Test ECS service deployment
  - [ ] Verify health checks pass
  - [ ] Test rollback on failed health check
  - [ ] Test frontend deployment to S3
  - [ ] Test CloudFront invalidation

- [ ] **End-to-End**
  - [ ] Make code change and push to develop
  - [ ] Verify CI runs and passes
  - [ ] Verify Docker images build
  - [ ] Verify deployment to staging
  - [ ] Test production deployment with approval
  - [ ] Verify logs in CloudWatch contain trace IDs

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-30 | 1.0 | Initial story creation | Sarah |

---

## Dev Agent Record

### Agent Model Used
_To be populated during implementation_

### Debug Log References
_To be populated during implementation_

### Completion Notes List
_To be populated during implementation_

### File List
_To be populated during implementation_

---

## QA Results
_To be populated by QA Agent_
